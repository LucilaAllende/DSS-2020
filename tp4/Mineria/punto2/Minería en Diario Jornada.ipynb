{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mineria en Diario Jornada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Desarrollar un crawler para el sitio web del Diario Jornada, que almacene la información de las secciones más relevantes de la página en una base de datos (puede usar Python + BeautifulSoup). Con la información recabada, resolver y graficar las siguientes operaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Desarrolar un Scraper (realizado con Scrapy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.item import Field\n",
    "from scrapy.item import Item\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.loader.processors import MapCompose\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from scrapy.loader import ItemLoader\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('resultados.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Articulo(Item):\n",
    "    fecha = Field()\n",
    "    seccion = Field()\n",
    "    titulo = Field()\n",
    "    visitas = Field()\n",
    "    texto = Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jornada(CrawlSpider):\n",
    "    items = []\n",
    "    name = \"Scraper-Jornada\"\n",
    "    custom_settings = {\n",
    "        'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',\n",
    "        'CLOSESPIDER_PAGECOUNT': 200,\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'jornada.json'                        # Used for pipeline 2\n",
    "    }\n",
    "\n",
    "    download_delay = 5\n",
    "\n",
    "    allowed_domains = [\"www.diariojornada.com.ar\"]\n",
    "\n",
    "    start_urls = [\n",
    "        \"https://www.diariojornada.com.ar/provincia/\",\n",
    "        \"https://www.diariojornada.com.ar/policiales/\",\n",
    "        \"https://www.diariojornada.com.ar/economia/\",\n",
    "        \"https://www.diariojornada.com.ar/sociedad/\",\n",
    "        \"https://www.diariojornada.com.ar/paismundo/\"\n",
    "    ]\n",
    "\n",
    "    rules = (\n",
    "        # Detalles de los articulos\n",
    "        Rule(\n",
    "            LinkExtractor(\n",
    "                allow=r'/283[5-8]\\d+'\n",
    "            ), follow=True, callback='parse_items'\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    def parse_items(self, response):\n",
    "        sel = Selector(response)\n",
    "        item = ItemLoader(Articulo(), sel)\n",
    "        \n",
    "        item.add_xpath(\n",
    "            'fecha', '//span[@id=\"ContentPlaceHolder1_lbl_Fecha\"]/text()')\n",
    "        item.add_xpath(\n",
    "            'seccion',\n",
    "            '//div[@class=\"well-body\"]/h3/a/text()')\n",
    "\n",
    "        item.add_xpath('titulo',\n",
    "                       '//div[@class=\"well-body\"]/h1/span[@id=\"ContentPlaceHolder1_lbl_Titulo\"]/text()')\n",
    "\n",
    "        item.add_xpath('visitas', '//div[@class=\"p-05\"]/span/text()')\n",
    "        item.add_xpath('texto', '//div[@id=\"cuerpo\"]/p/text()')\n",
    "\n",
    "        yield item.load_item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-25 12:00:31 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: scrapybot)\n",
      "2020-09-25 12:00:31 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Jul 17 2020, 12:50:27) - [GCC 8.4.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.1.4, Platform Linux-5.4.0-48-generic-x86_64-with-Ubuntu-18.04-bionic\n",
      "2020-09-25 12:00:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2020-09-25 12:00:31 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'CLOSESPIDER_PAGECOUNT': 200,\n",
      " 'LOG_LEVEL': 30,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'}\n",
      "2020-09-25 12:00:31 [py.warnings] WARNING: /home/lucila/.local/lib/python3.6/site-packages/scrapy/extensions/feedexport.py:239: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'\n",
    "})\n",
    "\n",
    "process.crawl(Jornada)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo un json con los 200 articulos scrapeados llamado 'jornada.json', que se puede encontrar en este directorio.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Mostrar cuáles son las 5 noticias más relevantes según cantidad de visitas a nivel global ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titulo: Renunció el diputado que besó los senos de su mujer en plena sesión virtual. Fecha: 24/09/2020 18:56. \n",
      "Seccion: PAÍS & MUNDO. Visitas: 6387.\n",
      "\n",
      "Titulo: Trelew: se sacó la tobillera y se escapó . Fecha: 24/09/2020 02:00. \n",
      "Seccion: POLICIALES. Visitas: 6244.\n",
      "\n",
      "Titulo: Madryn: se accidentó haciendo motocross y murió. Fecha: 24/09/2020 19:56. \n",
      "Seccion: POLICIALES. Visitas: 5957.\n",
      "\n",
      "Titulo: “La heladera está vacía”. Fecha: 23/09/2020 02:00. \n",
      "Seccion: PROVINCIA. Visitas: 5946.\n",
      "\n",
      "Titulo: Insólito: vecinos hicieron retirar de una rotonda estatuas de peces porque parecen \"penes\". Fecha: 21/09/2020 21:08. \n",
      "Seccion: SOCIEDAD. Visitas: 5445.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 noticias mas releventes a nivel global \n",
    "with open('jornada.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "articulos_globales = []\n",
    "for articulo in data:\n",
    "    articulos_globales.append({\"titulo\":articulo['titulo'], \"visitas\":articulo['visitas'], \"fecha\":articulo['fecha'], \"seccion\":articulo['seccion']})\n",
    "    \n",
    "articulos_globales.sort(key=lambda ag: int(ag['visitas']), reverse=True)\n",
    "\n",
    "for ag in range(5):\n",
    "    print(\"Titulo: {0}. Fecha: {2}. \\nSeccion: {3}. Visitas: {1}.\\n\".format(articulos_globales[ag]['titulo'], articulos_globales[ag]['visitas'], articulos_globales[ag]['fecha'], articulos_globales[ag]['seccion']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mostrar cuáles son las 5 noticias más relevantes según cantidad de visitas por sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sección PROVINCIA\n",
      "\n",
      "Titulo: “La heladera está vacía”. Fecha: 23/09/2020 02:00. \n",
      "Visitas: 5946.\n",
      "\n",
      "Titulo: Hubo otros 200 casos y tres nuevos fallecidos por Covid-19 en Chubut. Fecha: 23/09/2020 23:00. \n",
      "Visitas: 4275.\n",
      "\n",
      "Titulo: Chubut comienza a negociar un salvataje de Nación: uno por uno, el equipo de funcionarios que viajó a Buenos Aires. Fecha: 23/09/2020 02:00. \n",
      "Visitas: 3856.\n",
      "\n",
      "Titulo: Hubo otro récord de casos en un día (247) y cuatro nuevos fallecidos en Chubut por Covid-19. Fecha: 22/09/2020 23:26. \n",
      "Visitas: 3646.\n",
      "\n",
      "Titulo: En Chubut hubo 115 nuevos casos de Covid-19 y otros tres fallecidos. Fecha: 21/09/2020 23:21. \n",
      "Visitas: 3572.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 noticias mas releventes de seccion Provincia\n",
    "with open('jornada.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    \n",
    "#seccion Provincia\n",
    "articulos_provincia = []\n",
    "seccion_provincia = \"PROVINCIA\"\n",
    "for art in articulos_globales:\n",
    "    if art['seccion'] == seccion_provincia:\n",
    "        articulos_provincia.append(art)\n",
    "\n",
    "articulos_provincia.sort(key=lambda ap: int(ap['visitas']), reverse=True)\n",
    "\n",
    "print(\"Sección PROVINCIA\\n\")\n",
    "for ag in range(5):\n",
    "    print(\"Titulo: {0}. Fecha: {2}. \\nVisitas: {1}.\\n\".format(articulos_provincia[ag]['titulo'], articulos_provincia[ag]['visitas'], articulos_provincia[ag]['fecha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sección POLICIALES\n",
      "\n",
      "Titulo: Trelew: se sacó la tobillera y se escapó . Fecha: 24/09/2020 02:00. \n",
      "Visitas: 6244.\n",
      "\n",
      "Titulo: Madryn: se accidentó haciendo motocross y murió. Fecha: 24/09/2020 19:56. \n",
      "Visitas: 5957.\n",
      "\n",
      "Titulo: Incendio en Trelew: murieron dos perros y un hombre perdió todo. Fecha: 22/09/2020 09:26. \n",
      "Visitas: 4969.\n",
      "\n",
      "Titulo: Detectaron un micro con 22 permisos truchos en el ingreso Norte a Trelew. Fecha: 24/09/2020 12:22. \n",
      "Visitas: 3116.\n",
      "\n",
      "Titulo: Trelew: triple choque dejó a un conductor hospitalizado. Fecha: 24/09/2020 02:00. \n",
      "Visitas: 2766.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 noticias mas releventes de seccion Policiales\n",
    "with open('jornada.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "#seccion Policiales\n",
    "articulos_policiales = []\n",
    "seccion_policiales = \"POLICIALES\"\n",
    "for art in articulos_globales:\n",
    "    if art['seccion'] == seccion_policiales:\n",
    "        articulos_policiales.append(art)\n",
    "\n",
    "articulos_policiales.sort(key=lambda ap: int(ap['visitas']), reverse=True)\n",
    "\n",
    "print(\"Sección POLICIALES\\n\")\n",
    "for ag in range(5):\n",
    "    print(\"Titulo: {0}. Fecha: {2}. \\nVisitas: {1}.\\n\".format(articulos_policiales[ag]['titulo'], articulos_policiales[ag]['visitas'], articulos_policiales[ag]['fecha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sección ECONOMIA\n",
      "\n",
      "Titulo: El Presidente anunció líneas de financiamiento y pidió cuidar los dólares para la producción. Fecha: 22/09/2020 10:28. \n",
      "Visitas: 606.\n",
      "\n",
      "Titulo: El Producto Bruto Interno retrocedió 19,1% en el segundo trimestre del año. Fecha: 22/09/2020 16:15. \n",
      "Visitas: 394.\n",
      "\n",
      "Titulo: El Ministerio de Agricultura confía en otra cosecha récord de maíz. Fecha: 23/09/2020 10:58. \n",
      "Visitas: 391.\n",
      "\n",
      "Titulo: La pandemia provoca fuerte caída de ingresos a los trabajadores del mundo. Fecha: 23/09/2020 12:09. \n",
      "Visitas: 390.\n",
      "\n",
      "Titulo: El Producto Bruto Interno retrocedió 19,1% en el segundo trimestre del año. Fecha: 22/09/2020 16:15. \n",
      "Visitas: 385.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 noticias mas releventes de seccion Economia\n",
    "with open('jornada.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "#seccion Economia\n",
    "articulos_economia = []\n",
    "seccion_economia = \"ECONOM\\u00cdA\"\n",
    "for art in articulos_globales:\n",
    "    if art['seccion'] == seccion_economia:\n",
    "        articulos_economia.append(art)\n",
    "\n",
    "articulos_economia.sort(key=lambda ap: int(ap['visitas']), reverse=True)\n",
    "\n",
    "print(\"Sección ECONOMIA\\n\")\n",
    "for ag in range(5):\n",
    "    print(\"Titulo: {0}. Fecha: {2}. \\nVisitas: {1}.\\n\".format(articulos_economia[ag]['titulo'], articulos_economia[ag]['visitas'], articulos_economia[ag]['fecha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sección SOCIEDAD\n",
      "\n",
      "Titulo: Insólito: vecinos hicieron retirar de una rotonda estatuas de peces porque parecen \"penes\". Fecha: 21/09/2020 21:08. \n",
      "Visitas: 5445.\n",
      "\n",
      "Titulo: Viral: aprovechó su cumpleaños y \"deschavó\" al novio y su mejor amiga, que la engañaban. Fecha: 24/09/2020 21:25. \n",
      "Visitas: 4858.\n",
      "\n",
      "Titulo: Video impresionante: escalaban un iceberg y se les dio vuelta en medio del mar. Fecha: 21/09/2020 19:41. \n",
      "Visitas: 2719.\n",
      "\n",
      "Titulo: Los defensores de los imputados de “La Manada”  denuncian que el fiscal Rivarola “armó la causa”. Fecha: 25/09/2020 02:00. \n",
      "Visitas: 1019.\n",
      "\n",
      "Titulo: Un referente de entidad que niega la pandemia estafó a una obra social. Fecha: 23/09/2020 14:09. \n",
      "Visitas: 647.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 noticias mas releventes de seccion Sociedad\n",
    "with open('jornada.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# seccion Sociedad\n",
    "articulos_sociedad = []\n",
    "seccion_sociedad = \"SOCIEDAD\"\n",
    "for art in articulos_globales:\n",
    "    if art['seccion'] == seccion_sociedad:\n",
    "        articulos_sociedad.append(art)\n",
    "\n",
    "articulos_sociedad.sort(key=lambda ap: int(ap['visitas']), reverse=True)\n",
    "\n",
    "print(\"Sección SOCIEDAD\\n\")\n",
    "for ag in range(5):\n",
    "    print(\"Titulo: {0}. Fecha: {2}. \\nVisitas: {1}.\\n\".format(\n",
    "        articulos_sociedad[ag]['titulo'], articulos_sociedad[ag]['visitas'], articulos_sociedad[ag]['fecha']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sección PAIS & MUNDO\n",
      "\n",
      "Titulo: Renunció el diputado que besó los senos de su mujer en plena sesión virtual. Fecha: 24/09/2020 18:56. \n",
      "Visitas: 6387.\n",
      "\n",
      "Titulo: Argentina tiene \"nuevo mapa\" y Tierra del Fuego pasó a ser el centro del país. Fecha: 22/09/2020 19:58. \n",
      "Visitas: 3888.\n",
      "\n",
      "Titulo: La CGT quiere organizar una marcha el 17 de octubre en apoyo a Alberto Fernández. Fecha: 21/09/2020 19:09. \n",
      "Visitas: 516.\n",
      "\n",
      "Titulo:  “Es grave e inmoral”, dijo Rossi en Cadena Tiempo sobre el espionaje ilegal a familiares del ARA San Juan. Fecha: 24/09/2020 19:35. \n",
      "Visitas: 497.\n",
      "\n",
      "Titulo: El Gobierno aprueba el pago del ATP6 con salarios de septiembre. Fecha: 23/09/2020 15:58. \n",
      "Visitas: 488.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 noticias mas releventes de seccion Pais & Mundo\n",
    "with open('jornada.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# seccion Pais & Mundo\n",
    "articulos_paismundo = []\n",
    "seccion_paismundo = \"PA\\u00cdS & MUNDO\"\n",
    "for art in articulos_globales:\n",
    "    if art['seccion'] == seccion_paismundo:\n",
    "        articulos_paismundo.append(art)\n",
    "\n",
    "articulos_paismundo.sort(key=lambda ap: int(ap['visitas']), reverse=True)\n",
    "\n",
    "print(\"Sección PAIS & MUNDO\\n\")\n",
    "for ag in range(5):\n",
    "    print(\"Titulo: {0}. Fecha: {2}. \\nVisitas: {1}.\\n\".format(\n",
    "        articulos_paismundo[ag]['titulo'], articulos_paismundo[ag]['visitas'], articulos_paismundo[ag]['fecha']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
